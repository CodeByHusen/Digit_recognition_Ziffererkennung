\documentclass[
    12pt,
    oneside,
   ]{report}

  
\usepackage{url}
\usepackage{xcolor}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{colortbl}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{chngcntr}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath} 
\usepackage{wrapfig}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{listings}
\renewcommand\lstlistingname{Source Code}
\renewcommand\lstlistlistingname{Source Code}

\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codeorange}{rgb}{1,0.49,0}
\definecolor{backcolour}{rgb}{0.95,0.95,0.96}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegray},
    keywordstyle=\color{codeorange},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codegreen},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    xleftmargin=10pt,
}
\lstset{style=mystyle}


\usepackage[backend=biber]{biblatex}




\title{Projekt-Arbeit}
\author{Cynthia Odudu, Husen Muhsen , Carlo Wolter}
\date{Febuar 2023}

 



\setcounter{tocdepth}{1}
\counterwithout{figure}{chapter}
\counterwithout{table}{chapter}
 \renewcommand\labelitemi{$\diamond$}
\setlength{\parindent}{0pt}

\addbibresource{literatur.bib}
\begin{document}
\maketitle
 \newpage
\tableofcontents
\listoffigures
\lstlistoflistings




\chapter{Zielstellung }
Unsere Zielstellung ist der Bau eines Neuronen-Netzwerkes, welche handgeschriebene Ziffern erkennt. Eine Ziffernerkennung ist ein typisches Anwendungsgebiet für neuronale Netze. Hier geht es darum, Bilder von Ziffern als Eingabe zu nutzen und sie in die korrekte Ziffer (0 bis 9) einzustufen.

Die Zielstellung eines Ziffernerkennenden neuronalen Netzes ist es, eine hohe Genauigkeit bei der Klassifikation der Ziffern zu erreichen. Hierbei ist es wichtig, die unterschiedlichen Schreibweisen der Ziffern zu berücksichtigen und in der Lage zu sein, auch unvollständige oder verzerrte Ziffern zu erkennen.

Ein weiterer wichtiger Aspekt ist das Training des neuronalen Netzwerkes. Hierbei werden große Mengen an Bilddaten verwendet, um das Netzwerk darin zu trainieren, die Ziffern richtig zu erkennen. Es ist wichtig, eine ausreichende Vielfalt an Schreibweisen der Ziffern im Trainingsdatensatz zu berücksichtigen, um das Netzwerk für unterschiedliche Schreibweisen anfällig zu machen.

Während des Trainings werden die Gewichte und Verbindungen innerhalb des Netzes angepasst, um die Fehlerfunktion zu minimieren und die Vorhersagen des Netzes immer präziser zu machen. Hierbei kann es notwendig sein, mehrere Trainingsläufe durchzuführen, um eine bessere Leistung zu erreichen.

Die Zielstellung eines Ziffernerkennenden neuronalen Netzwerkes ist es also, eine hohe Genauigkeit bei der Klassifikation von Ziffernbildern zu erreichen, indem es große Mengen an Bilddaten verwendet, um das Netzwerk zu trainieren, und die Gewichte und Verbindungen anzupassen, um die Vorhersagen zu verbessern.

\chapter{Vorbereitung}
Im Rahmen des Projekts wurden von Cynthia Odudu die Themen Dokumentation des Quelltextes mittels Doxygen und Git-Lab Runner bearbeitet. Von Carlo Wolter wurden die Projektziele Unit Test sowie deren Auswertung (Laufzeit) übernommen. Das Projektziel der Implementation wurde zum Großteil von Husen Muhsen bearbeitet. Dabei haben Cynthia Odudu und Carlo Wolter bei der Erstellung des neuronalen Netzwerkes, sowie Erkennung der Buchstaben und Zahlen unterstützt. \\

Die Belegarbeit wurde in gleichen Teilen von allen Projektteilnehmern erstellt. Um ein effektives und präzises Neuronen-Netzwerk zu bauen, ist die Vorbereitung ein wichtiger Schritt. Dabei kann man sich an diesen wichtigen Schritten orientieren. Zuerst sollte man klären, welches Problem man gelöst haben will. \\

In diesem Projekt geht es um das Problem des Einlesens von handgeschriebenen Ziffern. Die Anforderungen an das Netzwerk ist somit die Auswertung von Dateien mit handgeschriebenen Ziffern. Für die Problemlösung stand ein großer Datensatz zur Verfügung. Der Datensatz beinhaltete zusätzlich Trainingssets, welche die zu repräsentierende Zahl beinhaltete. Dadurch kann ein Netzwerk offline trainiert werden.

Kennt man das Problem, benötigt man noch eine Architektur. Für Neuronen-Netzwerke gibt es einige unterschiedliche Architekturen, welche alle Vorteile haben. Beispiele für solche Architekturen sind das Perceptron und Feed Forward Networks, das MultiLayer Perceptron (MLP) und das Single layer Perception, siehe Kapitel 3.1.7. 

Es müssen sich auch Gedanken, um Parameter wie Anzahl der Neuronen, der Schichten und der Lehrling Rate gemacht werden. Hierbei ist es wichtig, geeignete Schätzwerte und experimentelle Methoden zu verwenden, um die besten Parameter zu ermitteln.

Damit ein Netzwerk mit Daten auch etwas anfangen kann, muss das Programm die Dateien erst in Daten umwandeln. Sie werden normalisiert, geschärft und gegebenenfalls aufgeteilt, um Overfitting zu vermeiden, siehe Herausforderungen und Kapitel 7.1. 

Um zu beurteilen, wie gut das Netzwerk funktioniert, muss das Model bewertet werden. Eine Fehlerfunktion kann diese Metriken (Messgrößen oder Kennzahlen) liefern.

\chapter{Neuronales Netzwerk}
Dieses Projekt stellt eine verständliche Untersuchung dar, wie neuronale Netze implementiert werden.  Das Ziel dieses Projekt ist es, dass Kernproblem des maschinellen Lernens via neuronale Netze mit mindestens zwei verschiedenen Varianten für Parallelität ohne Nutzung vorgefertigter Bibliotheken zu implementieren, die gemeinsam mit der sequenziellen Variante umfassend miteinander verglichen werden. Zu Beginn wird der Theorieteil des Neuronales Netzwerk zusammengefasst.
Der Begriff "neuronales Netz bzw. künstliche neuronale Netze (KNN)", beschreibt gewisse Strukturen im menschlichen Hirn. Sie sind ein Teil der Technologien, die in der Maschine verwendet werden und bilden die Grundlage für das Deep Learning.  \cite{Deeplearning}
\newpage
\section {\textbf{Deep Learning vs. Machine Learning}}

In diesem Kapitel wird das Deep Learning dem Machine Learning gegenübergestellt. Dies ist im nachfolgenden Abbildung \ref{abb:Deep Learning}dargestellt.

\begin{figure}[h]\centering
\begin{subfigure}[c]{0.6\textwidth}\centering
\includegraphics[width=\textwidth]{Bild1.png}\subcaption{How deep learning is a subset of machine learning and how machine learning is a subset of AL. }

\end{subfigure}
\hspace{0.2in}
\caption{Deep Learning \newline
(Quelle: https://bit.ly/3m03lmn (aufgerufen:19.02.2023,17:33))}

\label{abb:Deep Learning}

 \end{figure}

 \section{Künstliche neuronale Netze (KNN) (AI)}
Neuronale Netze zeichnen sich dadurch aus, dass Computer mit ihrer Hilfe eigenständig Probleme lösen und ihre Fähigkeiten verbessern können. 
Ein Neuron kann dabei viele Eingänge, zum Beispiel (Zahlenwerte) haben, wenn diese Zahlenwerte dann den Schwellwert überschreiten, gibt das Neuron ein Ausgabewert aus. Für jeden Eingangskanal des Neurons gibt es ein sogenanntes Gewicht und Schwellwert, der eingestellt werden muss. \\

\section{Machine Learning}
Machine Learning ist der Einsatz und Entwicklung von Computersystemen, die in der Lage sind, zu lernen und sich anzupassen, ohne ausdrückliche Anweisungen zu befolgen, indem sie Algorithmen und statistische Modelle verwenden, um Daten zu analysieren und aus Mustern Schlüsse zu ziehen. \cite{Deeplearning} \\



 
\section{Deep Learning }

Deep Learning ist eine Teilmenge des maschinellen Lernens auf der Grundlage künstlicher neuronaler Netze, bei der mehrere Verarbeitungsebenen verwendet werden, um schrittweise höherwertige Merkmale aus Daten zu extrahieren. Jeder Deep Learning-Algorithmus wird als maschinelles Lernen betrachtet, aber nicht jeder Algorithmus des maschinellen Lernens wird als Deep Learning betrachtet. \cite{Deeplearning} \newpage




\section{Gewicht}
Das Gewicht ist der Parameter in einem neuronalen Netz, der die Eingabedaten in den verborgenen Schichten des Netzes umwandelt. Jede Schicht hat eigene Gewichte zur Folgeschicht, je grösser das Netz, desto mehr Gewichte hat man. Hat man beispielsweise ein Netz mit 3 Schichten à 3 Knoten, sind das insgesamt 18 Gewichte.
(Alle 3 Knoten der ersten Schicht verbunden mit allen 3 Knoten der zweiten
Schicht = 9 Gewichte. Dann nochmals 9 Gewichte für die Knoten der zweiten zur dritten Schicht = 18 Gewichte total). Die Gewichtung dieser Verbindungen definiert hierbei, wie wichtig eine Verbindung im Netzwerk ist. Durch das Trainieren des KNN passt sich diese Gewichtung an und kann sich im Laufe des Trainings verändern.\\

Das Lernen eines neuronalen Netzes ist also tatsächlich die Anpassung dieser Gewichte.
Ein neuronales Netz ist definiert durch die Anzahl der Eingangsknoten (Input layer), die Anzahl der verborgenen Schichten (hidden layer), die Anzahl der Knoten in jeder versteckten Schicht und die Anzahl der Knoten in der letzten Schicht (Output layer).
Die Eingabeschicht (input layer) empfängt Daten bzw. nimmt die Eingabeinformation, wie beispielsweise Bilder von Hunden und Katzen, auf. Diese werden dann als Wert an das Netz bzw. die nachfolgenden verborgenen Schichten (Hidden layers) weitergegeben. Diese führt mathematische Berechnungen an den Informationen durch, lernt die Abbildungsfunktion zwischen Eingabe und Ausgabe. Die verborgenen Schichten, von denen es beliebig viele geben kann, errechnen anhand der vorhandenen Informationen die Ausgabe (output layer). Die Output layer liefert das Ergebnis (siehe Abbildung \ref{abb:Architektur eines künstlichen neuronalen Netzes})  . In der Abbildung repräsentiert jeder Pfeil von einem Knoten zum nächsten ein Gewicht.\cite{KONZEPTE}

 \begin{figure}[h]\centering
\begin{subfigure}[c]{0.7\textwidth}\centering
\includegraphics[width=\textwidth]{Bild2.jpg}
\end{subfigure}
\hspace{0.2in}
\caption{Architektur eines künstlichen neuronalen Netzes \\(Quelle: https://bit.ly/3YUNmEF (aufgerufen:19.02.2023,23:10))  }
\label{abb:Architektur eines künstlichen neuronalen Netzes}

\end{figure}

\newpage

\section{Schwellenwert}
Der Schwellenwert ist der Grenzwert der Funktion. Wird dieser also auf 0,5 gesetzt, bedeutet alles, was darunter liegt, eine Ausgabe von 0, und alles, was darüber liegt, eine Ausgabe von 1. Das Neuron hat keine erwünschte Ausgabe, sondern nur eine erwünschte Eingabe, damit es sagt: 8, die Daten sehen aus wie Daten, die ich sehen soll.\cite{KONZEPTE} \\ 

\newpage
\section{Funktionsweise auf Knotenebene}

\begin{figure}[h]\centering
\begin{subfigure}[c]{0.7\textwidth}\centering
\includegraphics[width=\textwidth]{Bild3.png}
\end{subfigure}
\hspace{0.2in}
\caption{Funktionsweise auf Knotenebene \\ (Quelle: https://bit.ly/3ZfAzfR (aufgerufen:19.02.2023,23:17))}
\label{abb:Funktionsweise auf Knotenebene}


\end{figure}
In der Abbildung \ref{abb:Funktionsweise auf Knotenebene} wird die Funktionsweise auf Knotenebene beschreiben. Jeder Knoten erhält eine Menge von Eingaben, die als $x$ bezeichnet werden. Jede dieser Eingaben hat ein Gewicht, in dem Fall mit $w$ betitelt. Werden Gewichtung $w$ und Wert $x$ multipliziert, dann erhalten wir die gewichtete Eingabe. 
\\

Das Gewicht entscheidet zusammen mit einer Übertragungsfunktion, über die Eingabe, die nun weitergeleitet wird. Die Übertragungsfunktion muss einfach dafür sorgen, dass aus diesen verschiedenen Zahlen, was in den Knoten übermittelt wird, nur noch ein Zahlenwert rauskommt. Aus diesem ergibt sich die tatsächliche Eingabe für den Knoten, indem alle gewichteten Eingaben aufsummiert werden. Ziel der Übertragungsfunktion ist es, aus den Inputs eine gemeinsame Darstellung zu generieren. Kurz gesagt, aus vielen wird eins. Diese aufsummierte Aufgabe bestimmt nun mithilfe der Aktivierungsfunktion die Ausgabe des Neurons (Y).  Die Aktivierungsfunktion modifiziert diesen Wert nocheinmal. Die Aktivierungsfunktion wird in einem sogenannten Schwellwert geschrieben. Er sorgt dafür, dass bei der Aktivierungsfunktion mindestens ein gewisser Wert ausgegeben werden muss. Wenn die Bedingung erfüllt ist, funktioniert das Ganze, ansonsten kommt null raus. \cite{NEURONALENETZE} \\

Es gibt Notationen, wodurch es eine Aktivierung und zusätzlich einen Schwellwert gibt. Manchmal ist die Schwellwert Funktion selber die Aktivierungsfunktion von den Neuronen.
Um den Ausgabewert eines einzelnen Neurons zu berechnen, multipliziert man jede Eingabe in dieses Neuron mit einer Gewichtung für diese Eingabe, addiert sie und fügt eine Vorspannung hinzu, die für das Neuron festgelegt wurde. Dieser \emph{gewichtete Eingabewert} wird in eine Aktivierungsfunktion eingegeben und das Ergebnis ist der Ausgabewert dieses Neurons. \cite{TheBlog}. In Abbildung \ref{abb: single neuron} ist ein einzelnes Neuron dargestellt.
\begin{figure}[h]\centering
\begin{subfigure}[c]{0.7\textwidth}\centering
\includegraphics[width=\textwidth]{Bild8.png}
\end{subfigure}
\hspace{0.2in}
\caption{Single neuron Quelle: (https://bit.ly/3XZkytv \newline (aufgerufen:19.02.2023)) }
\label{abb: single neuron}


\end{figure}

Als Aktivierungsfunktion verwenden wir eine gängige Funktion, die Sigmoid-Aktivierungsfunktion, die manchmal auch als logistische Aktivierungsfunktion bezeichnet wird. Sie sieht wie folgt aus:

 $$ \sigma(x)= \frac{\mathrm{1}}{\mathrm{1} + e^-^x } $$

\newpage

\section{Arten von neuronalen Netzen}
Es gibt viele Typen von neuronalen Netzwerk-Architekturen. Hier sind die wichtigsten Arten von neuronalen Netzen: 

\subsection{Perceptron und Feed Forward Networks}

Sie nutzen die Eingabedaten und berechnen daraus eine Ausgabe. Die Vorgehensweise erfolgt dabei in Schichten.
Das Perceptron ist sehr nützlich für die Klassifizierung von Datensätzen, die linear trennbar sind.  Bei Datensätzen, die diesem Muster nicht entsprechen, stößt es an ernste Grenzen, wie das XOR-Problem zeigt.  Das XOR-Problem zeigt, dass es für jede Klassifizierung von vier Punkten eine Menge gibt, die nicht linear trennbar ist.


\begin{figure}[h]\centering
\begin{subfigure}[c]{0.6\textwidth}\centering
\includegraphics[width=\textwidth]{Bild4.jpg}

\end{subfigure}
\hspace{0.2in}
\caption{XOR-Problem}
 \end{figure}
\subsection{Das MultiLayer Perceptron (MLP)}
 Das MultiLayer Perceptron durchbricht diese Einschränkung und klassifiziert Datensätze, die nicht linear trennbar sind.  Dazu verwenden sie eine robustere und komplexere Architektur, um Regressions- und Klassifizierungsmodelle für schwierige Datensätze zu lernen. Bias wird hier gebraucht.
Die Hauptfunktion eines Bias besteht darin, jedem Knoten einen trainierbaren konstanten Wert zu geben (zusätzlich zu den normalen Eingaben, die der Knoten erhält).
Es ist unpraktisch, ein Bias-Neuron hinzuzufügen. Der Grund hierfür liegt darin, dass Sie gleichzeitig die Gewichtung und den Wert anpassen, so dass jede Änderung der Gewichtung die Änderung des Wertes, die für eine vorherige Dateninstanz nützlich war, neutralisieren kann.   \\

\subsection{Convolutional Neural Networks (CNN)}

Dies findet häufig Verwendung in der Bild- und Objekterkennung. \cite{datasolut}
\\

\subsection{Recurrent Neural Network}
Dies ist eine Art künstliches neuronales Netz, das häufig in der Spracherkennung und der Verarbeitung natürlicher Sprache eingesetzt wird. Rekurrente neuronale Netze erkennen die sequenziellen Merkmale von Daten und verwenden Muster, um das nächste wahrscheinliche Szenario vorherzusagen. \\

\subsection{Single layer Perception} Das sind neuronale Netze ohne hidden Schicht.


\section{Einsatzbereiche für Neural Networks}
Anwendungsbereiche sind beispielsweise die Text-, Bild- und Spracherkennung. Künstliche Neuronale Netze können zudem Simulationen und Prognosen für komplexe Systeme und Zusammenhänge erstellen ,wie in der Wettervorhersage, der medizinischen Diagnostik oder in Wirtschaftsprozessen.\cite{NeuralNetworks} Anwendungsfällen der selbstlernenden neuronalen Netze gehören: 
\\
\begin{itemize}
    \item die Sprachassistenten Alexa 
    \item Siri
    \item Googles Sprachassistent
    
\end{itemize}

 
\chapter{MNIST-Datenbank}

Der MNIST-Datensatz ist ein klassisches Problem für den Einstieg in die neuronalen Netze.
MnistData ist die Klasse, die den gesamten Code enthält, den wir zum Sammeln und Aufbereiten der Daten für unsere MNIST-Anwendung verwenden. 
Die MNIST-Datenbank (Modified National Institute of Standards and Technology database) ist eine große Datenbank mit handgeschriebenen Ziffern, die üblicherweise zum Training verschiedener Bildverarbeitungssysteme verwendet werden. Die Datenbank wird auch häufig zum Trainieren und Testen im Bereich des maschinellen Lernens verwendet. 
Sie enthält einen Trainingsdatensatz von 60.000 Beispielen und eine Testdatensatz von 10.000 Beispielen. Sie ist eine Teilmenge einer größeren Menge, die vom NIST zur Verfügung gestellt wird. Die Ziffern wurden größennormalisiert und in einem Bild fester Größe zentriert. \cite{MNIST-Datenbank} \newpage
\begin{figure}[h]\centering
\begin{subfigure}[c]{0.6\textwidth}\centering
\includegraphics[width=\textwidth]{Bild5.jpg}
\end{subfigure}
\hspace{0.2in}
\caption{Datensatz \\ (Quelle: https://bit.ly/3KwZ0kK \newline (aufgerufen: 20.02.2023)) }
\label{abb:Detensatz}
 \end{figure}


In der nachfolgenden Abbildung \ref{abb:Trainings und Testdatensatz}
 sieht man 4 Dateien. Sie ist eine gute Datenbank für alle, die Techniken des Lernens und Methoden der Erkennung von Fehlern an realen Daten ausprobieren möchten, ohne viel Aufwand für die Vorverarbeitung und Formatierung zu haben. \cite{MNIST}
\begin{figure}[h]\centering
\begin{subfigure}[c]{0.6\textwidth}\centering
\includegraphics[width=\textwidth]{Bild6.png}

\end{subfigure}
\hspace{0.2in}
\caption{Trainings und Testdatensatz }
\label{abb:Trainings und Testdatensatz}


 \end{figure}
 
\chapter{Backpropagation, Verlust und Epochen}\label{sec:Backpropagation}
Das wichtigste Element beim Training neuronaler Netze ist die Backpropagation. Backpropagation ist eine Kurzform für "backward Propagation". Backpropagation ermittelt die richtigen Gewichtungen, die auf Knoten in einem neuronalen Netz angewendet werden sollten, indem die aktuellen Ausgaben des Netzwerks mit den gewünschten oder richtigen Ausgaben verglichen werden. Die Differenz zwischen der gewünschten Ausgabe und der aktuellen Ausgabe wird durch den Verlust berechnet. Je kleiner der Verlust für ein Netzwerk ist, desto genauer wird es. 


 $$ f(m,b)= \frac{\mathrm{1}}{\mathrm{N} } \sum_{i=1}^{\mathrm{1}} (y_i -(mx_i-b))^2 \ $$


 Mathe ist der Schlüssel zu neuronalen Netzen. Der Vorgang, bei dem die Daten von der Eingabeschicht zur Ausgabeschicht und dann den ganzen Weg zurückgesendet werden, wird als Epoche bezeichnet. In jeder Epoche aktualisiert das Neuronale Netz die Gewichte der Neuronen, was auch als Lernen bezeichnet wird. Nach mehreren Epochen und Gewichtungsaktualisierungen sollte die Verlustfunktion (die Differenz zwischen der Ausgabe des neuronalen Netzes und der tatsächlichen Ausgabe) ein Minimum erreichen. \\
In der ersten Epoche werden die beschrifteten Daten in die Eingabeschicht eingegeben und an die Ausgabeschicht weitergeleitet, wo das Neuronale Netz eine Ausgabe berechnet. Die Differenz zwischen der tatsächlichen Ausgabe des Neuronalen Netzes und der erwarteten Ausgabe wird als Kostenfunktion bezeichnet. Das Ziel des neuronalen Netzwerks ist es, diese Kostenfunktion so weit wie möglich zu verringern. Das neuronale Netzwerk wird also von der Ausgabeschicht bis zur Eingabeschicht zurückverfolgt und die Gewichte der Neuronen entsprechend aktualisiert, um diese Kostenfunktion zu minimieren. \cite{KünstlichIntelligent}

\chapter{Training}
Beim Training wollen wir mit einem neuronalen Netz mit schlechter Leistung beginnen und am Ende ein Netz mit hoher Genauigkeit haben. In Bezug auf die Verlustfunktion wollen wir, dass unsere Verlustfunktion am Ende des Trainings viel niedriger ist als zu Anfang. Eine Verbesserung des Netzes ist möglich, da wir seine Funktion durch Anpassung der Gewichte ändern können. Wir wollen eine andere Funktion finden, die besser funktioniert als die ursprüngliche.
Ein neuronales Netz zu trainieren bedeutet einfach, dass wir die Werte für die Gewichtung und den Bias so anpassen, dass wir bei bestimmten Eingaben die gewünschten Ausgaben des Netzes erhalten. Herauszufinden, welche Gewichte und Verzerrungen zu verwenden sind, kann schwierig sein, insbesondere bei Netzen mit vielen Schichten und vielen Neuronen pro Schicht. \\

Es gibt eine Vielzahl von Algorithmen, die Funktionen optimieren. Diese Algorithmen können gradientenbasiert oder nicht gradientenbasiert sein, d.\,h, sie verwenden nicht nur die von der Funktion bereitgestellten Informationen, sondern auch ihren Gradienten \cite{Training}. Einer welchen wir benutzen können ist die Backprobagation. Dies ist die am häufigsten verwendete Methode für das Training neuronaler Netze.
Wie oben schon beschrieben  \ref{sec:Backpropagation}, Backpropagation  in neuronalen Netzen ist eine Kurzform für "Rückwärtsfortpflanzung von Fehlern". Es handelt sich um eine Standardmethode für das Training künstlicher neuronaler Netze. Diese Methode hilft bei der Berechnung des Gradienten einer Verlustfunktion in Bezug auf alle Gewichte im Netz. \\

 \section{
Warum die Backpropagation?
}
Beim Training neuronaler Netze wollen wir zunächst alle Werte der Neuronen berechnen und sehen, welche Ausgabeschicht dabei herauskommt (manchmal auch als forward pass bezeichnet). Wenn wir mit dem tatsächlichen Ergebnis konfrontiert werden, können wir die Verlustfunktion berechnen. Aber wir wollen das Netzwerk trainieren und daher versuchen, den Wert, den wir als Verlust erhalten haben, zu minimieren. In diesem Schritt müssen wir rückwärts gehen und prüfen, wie sich kleine Änderungen unserer Gewichte auf das Ergebnis auswirken würden, und die Gewichte entsprechend den Informationen über ihre Auswirkungen auf eine Verlustfunktion aktualisieren. Dazu müssen wir die partiellen Ableitungen der Verlustfunktion in Bezug auf jedes Gewicht und jede Verzerrung im Netz berechnen. \cite{BackPropagation}\\ 
In der nachfolgenden Abbildung \ref{abb: Überblick} ist das Übersicht über den Backpropagation-Algorithmus dargestellt.




 \begin{figure}[h]\centering
\begin{subfigure}[c]{0.7\textwidth}\centering
\includegraphics[width=\textwidth]{Bild10.png}
\end{subfigure}
\hspace{0.2in}
\caption{Überblick über der Backpropagation-Algorithmus (Quelle: \newline https://bit.ly/3kjNQW7(aufgerufen:23.02.2023, 22:35)) }
\label{abb: Überblick}

\end{figure}
So funktioniert der Backpropagation-Algorithmus


\caption{Funktionsweise auf Knotenebene \\ (Quelle: https://bit.ly/3ZfAzfR (aufgerufen:19.02.2023,23:17))}
\label{abb:Funktionsweise auf Knotenebene}

\begin{itemize}
    \item Die Eingaben X kommen über den vorverknüpften Pfad an.
    \item Die Eingabe wird durch reale Gewichte W modelliert. Die Gewichte werden normalerweise zufällig ausgewählt. 
    \item Die Ausgabe für jedes Neuron von der Eingabeschicht wird über die versteckten Schichten bis hin zur Ausgabeschicht wird berechnet.
    \item Es werden die Fehler in den Ausgaben berechnet.
    \item Es wird von der Ausgabeschicht zur versteckten Schicht(hidden layer) zurückgekehrt, um die Gewichte so anzupassen, dass der Fehler verringert wird.
    \item Der Vorgang wird wiederholt, bis das gewünschte Ergebnis erreicht ist.
\end{itemize}

Es gibt Zwei Arten von Backpropagation-Netzwerken:
\begin{itemize}
    \item Statische Backpropagation
    \item Rekurrente Backpropagation
\end{itemize}
Statische Backpropagation: Dies ist eine Art von Backpropagation-Netzwerk, das eine Abbildung einer statischen Eingabe auf eine statische Ausgabe erzeugt. Es ist nützlich, um statische Klassifizierungsprobleme wie optische Zeichenerkennung zu lösen. \\

Rekurrente Backpropagation: Bei der rekurrenten Backpropagation im Data Mining wird so lange weitergeleitet, bis ein fester Wert erreicht ist. Danach wird der Fehler berechnet und rückwärts propagiert.\\

Der Hauptunterschied zwischen diesen beiden Methoden besteht darin, dass die Zuordnung bei statischer Backpropagation schnell erfolgt, während sie bei rekurrenter Backpropagation nicht statisch ist \cite{BackPropagationarten}.
Um die Gewichte neu anzupassen, benötigen wir die Ableitung der Kostenfunktion nach W, da  \\diese uns sagt, wie sich die Kosten der Modellvorhersage ändern, wenn wir das Gewicht W ändern.
Diese Ableitung wird benötigt, um die Gradientenabstiegsmethode anzuwenden und die Gewichte entsprechend zu aktualisieren, um die Kosten zu minimieren und damit das Modell zu verbessern.
\begin{equation} 
\frac{\partial E}{\partial W_i} = \frac{1}{2} \sum_{x_i}^{x} = \frac{\partial}{\partial W_i}(y_i - y'_i )^2\notag
\end{equation}\\

\begin{equation} 
f(x)=g(h(x)) 	\Rightarrow \frac{\partial f(x)}{\partial x} = \frac{\partial g(h(x))}{\partial x} * \frac{\partial h(x)}{\partial x}\notag
\end{equation}\\

\begin{equation} 
\frac{\partial E}{\partial W_i} = \frac{1}{2} \sum_{x_i}^{X} 2 * (y - y'_i) \frac{\partial}{\partial x} (y - y'_i)\notag
\end{equation}\\

\begin{equation} 
y'_i = \frac{1}{1+e\textsuperscript{-\sum_{}{}(Weight*Input)+bias}}\notag
\end{equation}\\
Nach W ableiten:
\begin{equation}
\frac{\partial E}{\partial W_i} = \sum_{x_i}^{X}(y - y'_i) \frac{\partial}{\partial x} (-y'_i)\notag \\
\end{equation}

\begin{equation}
\frac{\partial E}{\partial W_i} = \sum_{x_i}^{X} (y_i -\varphi(W * X_i)) * -\varphi(W * X_i) * (1 -\varphi(W * X_i)) * X_i \notag
\end{equation}\\

die Gewichte anpassen durch: \\
\begin{equation}
W_n_e_w = W_a_l_t + (\frac{\eta}{batch size}) * \frac{\partial E}{\partial W_i}\notag
\end{equation}





\chapter{Implementation}
In diesem Kpitel wird der Aufbau des Programmes anhand der einzelen code Implementierungen beschrieben. \\

\section {Reader Construktor}
Zuerst soll die MNIST-Datenbankdateien von der folgenden \href{http://yann.lecun.com/exdb/mnist/}{Webseite} heruntergeladen heruntergeladen werden, um das Netzwerk mit dem Inhalt dieser Dateien zu trainieren und später zu testen. Daher soll eine Reader-Klasse erstellt werden, um den Inhalt der Dateien zu lesen. 
\\

\begin{lstlisting}[language=C++, caption={Reader Construktor}, label={code},mathescape=true, breaklines=true]
Reader()=default;
Reader(const char fName[])
{

	char c;
	int index = 0;

	ifstream infile;
        /// ios::in allows input (read operations)
        ///from a stream.
	infile.open(fName, ios::binary | ios::in);

        /// Calculates the number of characters in the
        ///transferred file
	f_Size = (int)filesize(fName);

        /// resize() resizes the vector 
	fMapV.resize(f_Size);

        /// The forloop continues until the last digit
        ///in the file is read
	for (int i = 0; i < f_Size; i++)
	{
	    /// read()copies a block of data
            /// read(where items ares tored, number of items to read)
		infile.read(&c, 1);

            /// store the read letter in the Vector
		fMapV[i] = c;
	}
        /// Close the file, to create the file
	infile.close();
	read_Header();

}

\end{lstlisting}






\textbf{fileMapV}: Ist ein Vector mit unsigned char Werten.\\
\textbf{ifstream}: Ist eine Dateibehandlungsklasse, die den Eingabedateistrom definiert und verwendet wird, um Daten aus einer Datei zu lesen.\\
\textbf{open( )}:Um die angegebene Datei zu öffnen.\\
\textbf{Ios::binary}:Um sicherzustellen, dass die Daten ohne die Zeilenumbrüche gelesen oder geschrieben werden.\\
\textbf{Ios::in}:Ermöglicht das Lesen von Eingaben aus einem Stream.\\
\textbf{resize(n)}:Änderung der Größe eines Vectors. n ist die neue Größe\\
\textbf{read(m, n)}:Diese Funktion kopiert einen Datenblock.\\
M: Speicherort der kopierten Elemente\\
N: Anzahl der zu lesende Elemente \\
\textbf{close( )}: Datei schließen. \\

\newpage
\section {Reader getter Funktion}
\textbf{1.  getFileSize}: Diese Funktion wird benötigt, um die Größe der Datei zu erfahren und um die Größe des Vectors fileMapV festzulegen.\\

%\begin{figure}[h]
%\centering
%\includegraphics[width=0.9\textwidth]{filesize.png}
%\caption{filesize Funkion}
%\end{figure}

\begin{lstlisting}[language=C++, caption=Filesize Funktion,mathescape=true, breaklines=true]
/// uses absolute positions in the stream
std::ifstream::pos_type filesize(const char* filename)
{
    /// ios::ate the stream's position indicator to
    ///the end when opening
    /// binary it is a binary file
    std::ifstream in(filename, std::ifstream::ate |std::ifstream::binary);

    /// tellg/() to know where the get pointer is
	return in.tellg();
}
\end{lstlisting}
\textbf{pos-type}: Wird verwendet, um auf eine absolute Position im Stream zu verweisen.\\
\textbf{Ifstream::ate}: Setzt den Cursor des Streams beim Öffnen auf das Ende des Streams.\\
\textbf{tellg()}: Wird verwendet, um die Position des Lesezeigers in einer Datei zu ermitteln. Es gibt die Anzahl der Bytes zurück.\\

\textbf{2.  getLabel}\\
Es soll eine getLabel Funktion implementiert, die 'getLabel'-Funktion gibt die korrekte Antwort für das trainierte Bild zurück. Die Zahl 8 repräsentiert eine Lücke in den Daten am Anfang der Labeldatei, die bei jeder Verwendung überschritten werden muss, um den richtigen Index zu erreichen.\\
%\begin{figure}[h]
%\centering
%\includegraphics[width=0.6\textwidth]{getlabel.png}
%\caption{getlabel}
%\end{figure}

\begin{lstlisting}[language=C++, caption=getLable,mathescape=true, breaklines=true]
int getLabel(int numIndex) const
{
    /// 8 for label file this is the gap after which the
    ///first pixel of an image begins a digit
    /// numIndex the position of a pixel
	return fMapV[numIndex + data_Index];
}
\end{lstlisting}


\textbf{3.  getPixel}\\
Es soll ein Funktion implementiert, für die Lücke von 16 Bits am Anfang und am Ende der Datei. Die Zahlen sind in Hexadezimal-Notation angegeben und müssen in Float-Werte umgewandelt werden, indem sie durch 255 geteilt werden.
%\begin{figure}[h]
%\centering
%\includegraphics[width=0.7\textwidth]{getpixel.png}
%\caption{getPixel}
%\end{figure}

\begin{lstlisting}[language=C++, caption=getPixel,,mathescape=true, breaklines=true]
///numIndex of this picture stands for the number
///at which the next picture in the fMapV
float getPixel(int numIndex) const
{
    /// numIndex stands for the gap between
    ///one picture and the next
    /// file train-images, this gap is 16 digits
	if (numIndex + data_Index >= fMapV.size())
	{
		return 0.0f;
	}
	/// store in a 16 bit hex number
	int a = fMapV[numIndex + data_Index];
	/// divide the number by 255 to return a number between
        /// 0 and 1 if it is not 0
	return ((float)a / 255);
}
\end{lstlisting}


\section {Layer Implementation}
Die Layer Implementierung wird in diesem Projekt genutzt, um die einzelen Neuronen zusammenzufügen und in einzelne Schichten zu unterteilen. Dies ist wichtig, um das Netzwek in wenigen Schritten anzupassen und gegebenenfalls zu beschleunigen.\\
\\
\textbf{1.  Layer Klasse:} \\ Mit der Implementierung des Layer-Konstruktors werden die Größen der einzelnen Schichten mithilfe der 'resize'-Funktion definiert. Die folgende Abbildung zeigt die Komponenten einer Schicht.\\
Die Komponenten einer Schicht hängen davon ab, ob es sich um ein Input-, Hidden- oder Output-Layer handelt. 'dCdW', 'dCdA' und 'dCdB' stehen für die Ableitungen der Kostenfunktion nach 'W', 'Bias' und 'A'. Die Abbildung 15 zeigt den Quellcode für den Layer-Konstruktor.\\


%\begin{figure}[h]
%\centering
%\includegraphics[width=0.6\textwidth]{layrt.png}
%\caption{Layer constructor}
%\end{figure} 

\begin{lstlisting}[language=C++, caption=Layer Constructor,mathescape=true, breaklines=true]
Layer::Layer(int n, int w){
	
    neuron_Count = n;
    weight_Count = w;
    /**
    * @brief Assignment of vectorsSize the number of neurons
    * The size of the array is determined by the "neuronCount"
    *variable, which is the number of neurons in the network
    * Within the loop, a list of weights is created for each
    *neuron, also specified by the weightCount variable.
    * The size of the list of weights thus corresponds to
    *the number of inputs for the neuron.
    * */	
	
    weight.resize(neuron_Count);
    for (int j = 0; j < neuron_Count; j++)
    {
       weight[j].resize(weight_Count);
    }
    bias.resize(neuron_Count);
    a.resize(neuron_Count);
    z.resize(neuron_Count);
    dCdA.resize(neuron_Count);
    dCdW.resize(neuron_Count);
    for (int i = 0; i < neuron_Count; i++)
    {
       dCdW[i].resize(weight_Count);
    }
       dCdB.resize(neuron_Count);
    reset();
    randomize();
	
}
\end{lstlisting}

\textbf{2.  reset function:}\\ Die Ableitungsvektoren sollten mit Null initialisiert werden, um Vermeidung von Fehlern zu gewährleisten. Ein solcher Fehler kann zum Beispiel durch das Hinzufügen einer Zahl zu einer nicht initialisierten Variablen entstehen.\\
Die Ableitungsvektoren sollten mit Null initialisiert werden, da sie in vielen Algorithmen verwendet werden, um den Gradienten einer Funktion zu berechnen. Wenn sie nicht mit Null initialisiert werden, kann es zu falschen Berechnungen und somit zu Fehlern in den Ergebnissen kommen. Außerdem kann es zu inkonsistenten oder unerwarteten Ergebnissen führen, wenn die Ableitungsvektoren von einer bereits veränderten oder verfälschten Werten ausgehen.\newpage
%\begin{figure}[h!]
%\centering
%\includegraphics[width=0.5\textwidth]{reset.png}
%\caption{Reset function}
%\end{figure}.\\


\begin{lstlisting}[language=C++, caption=Reset Funktion,mathescape=true, breaklines=true]
/**
 * @brief Reset values of these arrays to 0
 * to update the neural network weights and biases.
 * to ensure that the updated values of the weights
 * and biases are calculated correctly.
*/
void Layer::reset()
{
    //uses the std::fill function from the C++
    //standard library to reset the values of
    // all elements in the dCdA and dCdB arrays
    //to 0.0 in a single line of code.

    for (int j = 0; j < neuron_Count; j++)
    {
        dCdA[j] = 0.0f;
        dCdB[j] = 0.0f;
        for (int k = 0; k < weight_Count; k++)
        {
            dCdW[j][k] = 0.0f;
        }
    }
}


\end{lstlisting}

\textbf{3.  randomsize:}\\ Am Anfang werden die $w_i$ und $b_i$ durch Zufallszahlen definiert. Die Ergebnisse werden dann überprüft, um zu bestimmen, ob sie korrekt oder falsch sind. Mit dem Backpropagation-Algorithmus werden sie so lange angepasst, bis eine bestimmte Float-Zahl gefunden wird, die zu den richtigen Ergebnissen führt. Dies wird durch die Funktion erreicht:
\begin{equation}
f(x) = 2 \frac{ rand}{ rand-max}{-1}\notag
\end{equation} \\
\newpage
%\begin{figure}[h!]
%\centering
%\includegraphics[width=0.7\textwidth]{randomsize.png}
%\caption{Randomize Funktion}
%\end{figure}\\

\begin{lstlisting}[language=C++, caption=Randomize Funktion,mathescape=true, breaklines=true]
/**
* initialize the weights and biases of the
* "Layer" object to random values
*/
void Layer::randomize()
{
    for (int j = 0; j < neuron_Count; j++)
    // We divide rand_num by rand_mak to get a number between
    // 0 and 1 then multiply that by
    // 2 to fix errors, and then subtract -1 to get the correct
    //number, which is between 0 and 1 or 0 and -1

    {
        bias[j] = 2 * ((static_cast <float> (rand())) /
        (static_cast <float> (RAND_MAX))) - 1;

        for (int k = 0; k < weight_Count; k++)
        {
            weight[j][k] = 2 * ((static_cast <float> (rand()))
            / (static_cast <float> (RAND_MAX))) - 1;
        }
    }
}


\end{lstlisting}
Am Ende bekommt man zufällige Gleitkommazahlen zwischen 0 und 1 oder 0 und -1 \\


\section {Netzwerk}

Als erstes sollte ein Network Konstruktor initialisiert werden, mit der gegebenen Anzahl an Layers, Inputs, Hidden-Units und Outputs. Es sollte als nächstes prüfen, ob die Übergabeparameter gültig sind (mindestens 2 Layers, mindestens 1 Input und mindestens 1 Output). Wenn die Übergabeparameter ungültig sind, wird eine Fehlermeldung ausgegeben und das Programm beendet.
Ansonsten wird ein Array für die korrekten Antworten initialisiert, ein Array für die Layer definiert und mithilfe von \textit{new} dynamisch Speicherplatz reserviert. Danach werden die einzelnen Layer definiert, beginnend mit dem Input-Layer über die Hidden-Layers bis zum Output-Layer. Jeder Layer wird mit den passenden Anzahlen an Inputs und Gewichten initialisiert.\\

\begin{equation}
f(x) = \frac{1}{1+e^{-x}}\notag
\end{equation}

\textbf{2.  think Funktion:} \\In der think Funktion ist die Aktivierungsfunktion implementiert.

\begin{equation}
y_i = s \frac{1}{1+e^-\sum(W_i_j * V_i)+ b_i}\notag
\end{equation}\\



Die Funktion "think" wird genutzt, um den Wertebereich der Aktivierung jedes Neurons im Netzwerk zu berechnen.
Die "think" Funktion berechnet den Wertbereich der Aktivierung \textit{a} jedes Neurons in einer bestimmten Schicht des neuronalen Netzwerks, indem es die Summe der Produkte der aktivierten Neuronen in der vorhergehenden Schicht
\textbf{(previous-layer->a[k])} mit den entsprechenden Gewichten.\\
\textbf{(lyrList[i]->W[j][k])} berechnet und dann mit dem Bias-Wert.\\
\textbf{(lyrList[i]->bias[j])} addiert. Der resultierende Wert.\\
\textbf{(lyrList[i]->z[j])} wird anschließend durch die Anwendung der Sigmod-Funktion.\\
\textbf{(lyrList[i]->a[j] = sigmod(lyrList[i]->z[j]))} skaliert, um den endgültigen Wertbereich der Aktivierung \textit{a} des Neurons zu bestimmen. \newpage
%\begin{figure}[h!]
%\centering
%\includegraphics[width=0.85\textwidth]{think.png}
%\caption{think constructor}
%\end{figure}\\
\begin{lstlisting}[language=C++, caption=Think Funktion,mathescape=true, breaklines=true]
/**
* @brief activate the neural network and calculate
* the outputs for all neurons
*/
void Network::think()
{
    /// The loop calls the "fire" method for each layer,
    /// passing the previous layer as a parameter.
    for (int i = 1; i < n_Layers; i++)
        {
            ///store the previous layer in a pointer p
            Layer const * p = layer_List[i - 1];
            layer_List[i]->fire(p);
        }
    }
}

\end{lstlisting}


\textbf{3.  fire Funktion:}
Die Funktion 'fire' berechnet die Aktivierungen der Neuronen in der aktuellen Schicht (Layer) anhand der als Parameter übergebenen Aktivierungen aus der vorherigen Schicht (prevLayer).\\
Für jedes Neuron 'j' in der aktuellen Schicht berechnet es die gewichtete Summe der Aktivierungen aus der vorherigen Schicht 'z[j]' durch Iterieren über die Gewichte weight[j][k], die die vorherige Schicht mit der aktuellen Schicht verbinden, und fügt einen 'Bias-Term' hinzu Voreingenommenheit[j].\\
Schließlich wird die Aktivierungsfunktion, hier die \textbf{Sigmoidfunktion 1,0f / (1 + exp(-z[j]))}, auf die gewichtete Summe \textbf{z[j]} angewendet, um die Aktivierung \textbf{a[j]} des Neurons 'j' zu erzeugen.
%\begin{figure}[h!]
%\centering
%\includegraphics[width=0.85\textwidth]{fire.png}
%\caption{fire Funktion}
%\end{figure}\\
%\newpage

\begin{lstlisting}[language=C++, caption=Fire Funktion,mathescape=true, breaklines=true]
// The function takes in a pointer to a previous layer (prevLayer) 
void Layer::fire(Layer const *prevLayer)  
{
    for (int j = 0; j < neuron_Count; j++)
    {
        z[j] = 0.0f;
        for (int k = 0; k < weight_Count; k++)
        {
        //output from the previous layer and the weights
        //connecting the previous layer 
        //to the courrent layer

        z[j] += prevLayer->getActivation(k) * weight[j][k];
        }
        //followed by the addition of a bias term (bias[j])
        //and the application of an
        // "activation function" 
        z[j] += bias[j];
        //a[j] = sigmoid_func(z[j]);
        a[j] = 1.0f / (1 + exp(-z[j]));
    }
}
\end{lstlisting}


\textbf{4.  learn Funktion:}
Die Funktion \textit{Learn} implementiert den Backpropagation-Algorithmus zum Trainieren eines neuronalen Netzes.\\
Das Netzwerk hat ein Array von Schichten layer-List, und n-Layers gibt die Anzahl der Schichten an. n-Outputs und n-Hiddens geben die Anzahl der Ausgaben bzw. versteckten Neuronen an. Das Array correct-Answer speichert die erwarteten Ausgabewerte.\\

Die Funktion beginnt mit der Ausgangsschicht und berechnet den Gradienten der Kosten in Bezug auf die Aktivierungen \textbf{\textit{dCdA}} und Bias \textbf{\textit{dCdB}} für jedes Ausgangsneuron \textbf{\textit{j}}. Es aktualisiert auch die Gewichte \textbf{\textit{dCdW}}, die die Ausgangsschicht mit der vorherigen verborgenen Schicht verbinden. Die Gradientenberechnung verwendet die \textbf{\textit{inputdCdA-Funktion}}, um den Gradienten zu akkumulieren, die \textbf{\textit{movedCdW}} Funktion, um die Gewichtungen zu aktualisieren, und die „movedCdB“-Funktion, um die Abweichungen zu aktualisieren.\\

Die Funktion durchläuft dann die verborgenen Schichten vom Ende bis zum Anfang und berechnet den Gradienten \textbf\textbf{\textit{dCdA}} für jedes verborgene Neuron \textbf{\textit{j}} in jeder Schicht. Der Gradient wird mit der Funktion \textbf{\textit{movedCdA}} akkumuliert und basiert auf dem Gradienten der nächsten Schicht, \textbf{layer-List[i + 1]}, und der Ableitung der Aktivierungsfunktion \textbf{\textit{transform-Prime}}. Die Funktion aktualisiert auch die Gewichtungen und Vorspannungen, die die verborgene Schicht mit der vorherigen Schicht verbinden, indem sie die Funktionen \textbf{\textit{movedCdW}} und \textbf{\textit{movedCdB}} verwendet.\\

Die Lernrate \textit{learn-Rate} und die Stapelgröße \textit{batch-Size} werden verwendet, um die Aktualisierungen auf die Gewichtungen, Abweichungen und Aktivierungen zu skalieren, wo bei die Stapelgröße auf die Anzhal der Traningsbeispiele sich bezieht \cite{Implementation}.

%\begin{figure}[h!]
%\centering
%\includegraphics[width=0.75\textwidth]{learn.png}
%\caption{learn Funktion}
%\end{figure}\\
\begin{lstlisting}[language=C++, caption=Learn Funktion,mathescape=true, breaklines=true]
void Network::learn(float learn_Rate, int batch_Size) // stochastic gradient descent + back propegation
	{

		//Calculate Output Layer

		for (int j = 0; j < n_Outputs; j++)
		{
			layer_List[n_Layers-1]->inputdCdA((layer_List[n_Layers-1]->getActivation(j) - correct_Answer[j]) * transform_Prime(layer_List[n_Layers-1]->getZ(j)), j);

			for (int k = 0; k < n_Hiddens; k++)
			{
				layer_List[n_Layers-1]->movedCdW(-(learn_Rate / (float)batch_Size) * layer_List[n_Layers-1]->getdCdA(j) * layer_List[n_Layers-2]->getActivation(k), j, k);
			}

			layer_List[n_Layers-1]->movedCdB(-(learn_Rate / (float)batch_Size) *  layer_List[n_Layers-1]->getdCdA(j), j);
		}

		//Calculate Hidden Layers

		for (int i = (n_Layers - 2); i > 0; i--)
		{
			for (int j = 0; j < layer_List[i]->getNumNeurons(); j++)
			{
				layer_List[i]->inputdCdA(0.0f, j);

				for (int k = 0; k < layer_List[i + 1]->getNumNeurons(); k++)
				{
				    layer_List[i]->movedCdA(layer_List[i + 1]->getWeight(k,j) * layer_List[i + 1]->getdCdA(k) * transform_Prime(layer_List[i]->getZ(j)), j);
				}

				for (int k = 0; k < layer_List[i - 1]->getNumNeurons(); k++)
				{
					layer_List[i]->movedCdW(-(learn_Rate / (float)batch_Size) * layer_List[i]->getdCdA(j) * layer_List[i - 1]->getActivation(k), j, k);
				}

				layer_List[i]->movedCdB(-(learn_Rate / (float)batch_Size) * layer_List[i-1]->getdCdA(j), j);
			}
		}
	}
}

\end{lstlisting}

In der \textit{learn} Funktion werden die neue Gewichte durch die Implementation folgende Gleichungen berechnet:
\begin{equation}
W_n_e_w = W_a_l_t + (\frac{\eta}{batch size}) * \frac{\partial E}{\partial W_i}\notag
\end{equation}

\begin{equation}
B_n_e_w = B_a_l_t + (\frac{\eta}{batch size}) * \frac{\partial E}{\partial A_i}\notag
\end{equation}

Im nächsten Schritt wurde eine Benutzeroberfläche erstellt, um die MNIST-Datenbank zu testen. Dies ist in Abbildung \ref{abb: UI} zu sehen.

\begin{figure}[h!]
\centering
\includegraphics[width=1\textwidth]{UI.png}
\caption{UI für das Program}
\label{abb: UI}
\end{figure}
\newpage
Dem Benutzer stehen drei Optionen zur Verfügung:
\begin{enumerate}
\item Die Laufzeit von \textit{Think- und Learn-Phasen} kann gemessen werden, indem vier verschiedene Architekturen getestet werden: \textit{SISD, SIMD, Parallel und Parallel und SIMD}.
\item Der Benutzer kann die \textit{MNIST-Daten} testen und die entsprechenden Ergebnisse ausgeben lassen. Dabei können benutzerdefinierte Daten eingegeben werden, wie z.B. welcher Architekturen ausgewählt werden sollen, welche Anzahl an Hidden Layers oder welche Lernrate verwendet werden soll.
\item Bei der dritten Option wird alles automatisch mit Standardeingaben erledigt. Die Anzahl der \textit{Hidden Layers} und die Lernrate sind bereits vorgegeben.
\end{enumerate}
%\end{figure}\\

\section {Unit-Test}
Um die erstellten Funktionen zu testen haben wir ein Unit-Test erstellt. Der Unit-Test setzt sich in diesem Projekt aus der Unit-Test Datei und dem XOR-problem Verzeichnis, siehe \cite{git} zusammen. Da in diesem Projekt viele Mathematischen Formeln benutzt wurden, konnten nicht alle Funktionen des Netzes getestet werden. Die Unit-Tests wurden genutzt, um damit Funktionalität zu beweisen und auf Fehlersuche zu gehen.
In der Unit-Test Datei wurde die Parameterübergabe der Layer Klasse getestet und im XOR-problem Verzeichnis wurden die Lern und Think Funktionen getestet.

\section{GitLab-Runner}
\textit{GitLab-Runner} ist ein Open-Source-Tool, das von GitLab bereitgestellt wird und als Continuous Integration (CI)- und Continuous Deployment (CD)-Agent für \textit{GitLab} fungiert. Mit \textit{GitLab} Runner kann man \textit{Builds, Tests und Deployments} automatisch ausführen, um sicherzustellen, dass die Anwendungen schnell und zuverlässig sind.

\textit{GitLab-Runner} kann in verschiedenen Modi ausgeführt werden, wie z.B. als \textit{Shell-Executor, Docker-Executor oder Kubernetes-Executor}, um Builds in isolierten Umgebungen auszuführen. Diese Modi ermöglichen Builds in einer konsistenten Umgebung auszuführen und die Abhängigkeiten der Anwendungen zu verwalten\cite{GitLab-Runner}.

Bevor wir unser Projekt abgeben möchten, werden die Server von \textit{GitLab-Runner} abgeschaltet (Shared-Runner), weshalb wir unseren eigenen \textitGitLab-Runner} zum System hinzufügen müssen. Wir haben uns für \textit{Docker Alpine} entschieden, da es schnell ausgeführt werden kann und im Vergleich zu anderen Images weniger Ressourcen benötigt. Dadurch können Builds und Tests schneller ausgeführt werden und es wird weniger Speicherplatz auf dem Host-System benötigt.



Insgesamt ist \textit{GitLab-Runner} ein nützliches Tool für Entwickler, um sicherzustellen, dass die Anwendungen schnell und zuverlässig sind, indem sie \textit{Builds, Tests und Deployments} automatisieren\cite{GitLab-Runner-2}.




\chapter{Laufzeit}
Die Laufzeit eines Neuronen-Netzwerkes hängt von verschieden Faktoren ab. Beispiele sind: Geschwindigkeit des Prozessors, größe des Netzwerkes, Anzahl der Neuronen und Schichten, Anzahl der Trainingsdateien sowie der Optimierungsalgorithmus. Die Anzahl der Neuronen und Schichten spielen hierbei eine große Rolle. Zu viele Neuronen/Schichten erhöhen die Laufzeit proportional.\\
\\
Die Wahl des Optimierungsalgorithmus ist wichtig, abhängig von der Schnelligkeit oder Genauigkeit. Ein schnellerer Optimierungsalgorithmus hat unter umständen eine geringe Genauigkeit als eine langsamer Optimierungsalgorithmus. \\

Die Laufzeit kann verbessert werden, in dem die Threads des Prozessors Parallel laufen. In diesem Projekt wurde OpenMP zum Parallelisieren verwendet, siehe Quellen (5). OpenMP ermöglicht es einfach Anwendungen parallel laufen zu lassen. Abschnitte eines Codes können für die Parallelisierung gekennzeichnet werden, wodurch OpenMP diesen Abschnitt auf mehreren Prozessorkernen ausführt und damit die Laufzeit erheblich verkürzen kann. Parallelisierung wird häufig verwendet, um die Berechnung von Neuronen und Schichten parallel auszuführen.\\ 
Parallele Ausführung kostet allerdings auch mehr Speicher und erhöht die Fehleranfälligkeit des Netzwerkes. Daher ist auf eine geschickte Anwendung zu achten.\\

Für das Projket wurden vier Architekturen (\textit{sisd, simd, parallel, simd und parallel}) verwende:\\
\textbf{SISD} (Single Instruction Single Data), ist die klassische Cpmputerarchitektur. Hier führt eim einziger CPU Kern eine einzige Anweisung auf ein Datenelement aus.\\

\textbf{SIMD} (Single Instruction Multiple Data) ermöglicht eine beschleunigte Datenverarbeitung. Hier wird eine gleiche Anweisung gleichzeitig auf mehrere Datenelemente angewendet.\\

\textbf{Parallel} bedeutet, dass mehrere CPU-Kerne gleichzeitig mehrere Anweisungen ausführen, um die Geschwindigkeit der Verarbeitung zu erhöhen.\\

\textbf{simd-parallel} ist eine spezielle Form der parallelen Verarbeitung, bei der SIMD-Technologie genutzt wird, um die Verarbeitungsgeschwindigkeit noch weiter zu beschleunigen.\\

Bei der Verarbeitung der MNIST-Datenbank für neuronale Netze kann die Verwendung von Parallel- oder SIMD-Architekturen die Geschwindigkeit der Verarbeitung verbessern, im Vergleich zu einer SISD-Architektur. Bei diesem Projekt man kann anhand die Laufzeitzhalen, siehe \cite{git} feststellen, das \textit{simd-paralle} schneller als simd und parallel ist.\\ \\
Um das Projekt zu evaluieren, wird eine Laufzeitmessung für verschiedene Architekturen durchgeführt, einschließlich \textit{SISD, SIMD, parallel, und SIMD & parallel}. Die Messungen werden auf einem Linux-System (Ubuntu 20.04.5 LTS) durchgeführt. Der Prozessor stammt von der Firma \textit{AMD} (Ryzen 5 2600 Six-Core Processor x 12).. Diese Messung dient dazu, die Leistung der verschiedenen Architekturen miteinander zu vergleichen. Hierbei werden die Ausführungszeiten für die Funktionen \textit{Think und Learn} gemessen. Es ist wichtig, sicherzustellen, dass das Programm für jede Architektur optimiert ist, um die bestmögliche Leistung zu erzielen. \\ Die gemessene \textit{Think und Learn} sind in der nachfolgenden Abbildung \ref{abb:learn time}  und Abbildung \ref{abb: think time} dargestellt. \newpage
\begin{figure}[h!]
\centering
\includegraphics[width=1\textwidth]{learn time.png}
\caption{learn time}
\label{abb:learn time}
\end{figure}\\
Die Ergebnisse werden auf einem \textit{Linux-Betriebssystem} durchgeführt, wobei die Lern- und Denkzeit gemessen wird. Die Messungen sind abhängig von der Anzahl der \textit{hidden layers} (von 10 bis 60). Anhand von Abbildung 19 und 20 lässt sich feststellen, dass die Zeit bei \textit{sisd} am längsten und bei \textit{parallel und parallel-simd} am kürzesten ist. Zum Beispiel beträgt die Denkzeit bei 60 \textit{hidden layers} bei sisd fast 30, während sie bei \textit{parallel und parallel-simd} fast 15 beträgt. Parallel-simd ist schneller, da diese Instruktionen nicht sequentiell (veraurbeitung in einer bestimmten Reinfolge) arbeitet, sondern die gleichen Operation auf mehrere Daten gleichzeitig angewenden. Das ist gerade bei großen Datenmengen sehr Sinnvoll. Somit können mehrere Pixel einer Handgeschriebenen Zahl auf einmal bearbeitet werden, um damit das Netzwerk schneller zu machen.  \\

\begin{figure}[h!]
\centering
\includegraphics[width=1\textwidth]{think time.png}
\caption{think time}
\label{abb: think time}
\end{figure}\\
Die MNIST-Datenbank habe wir mit verschiedenen Einstellungen getestet, und das Gesamtergebnis betrug eine korrekte Antwortrate von 93,33\%. Bei diesem Test wurden 60 Hidden Layers und eine Lernrate von 1.0.F mit dem parallelen verwendet. Die gesamte MNIST-Datenmenge wurde dabei geprüft, einschließlich 60.000 Trainingsbildern und 10.000 Testbildern.


\chapter{Herausforderung}
Der Bau eines Neuronen-Netzwerkes stellt viele Herausforderungen dar. Um ein effizientes und präzises Netzwerk zu erhalten gibt es einiges zu beachten:\\

 \section{Datenaufbereitung}
 Datenaufbereitung ist ein wichtiger Teil des Projektes. Damit ein Neuronen-Netzwerk Daten verarbeiten kann, müssen die Daten erst aufbereitet und gereinigt werden, \cite{Over/Underfitting}.\\
 

 \section{Over- / Unerfitting}
Over- und Underfitting sind zwei Herausforderungen, welche Schwierigkeiten darstellen. Wenn sich das Netzwerk zu sehr auf die Trainingsdaten anpasst, spricht man von Overfitting. Das Netzwerk kann in diesem Fall die Trainingsdaten sehr gut auswerten, die Testdaten hingegen haben eine hohe Fehlerquote. Overfitting kann auftreten, wenn das Netzwerk zu viele Freiheiten hat und zu Komplex ist.
Underfitting tritt auf, wenn das Netzwerk nicht in der Lage ist die komplexen Beziehungen der Trainingsdaten zu erfassen. Somit ist die Leistung des Netzwerkes sowohl bei den Trainingsdaten als auch bei den Testdaten gering.
Um Over und Underfitting zu vermeiden kommt es darauf an den richtigen grad an Komplexität zu finden. Dafür gibt es Methoden, welche helfen den richtigen grad an Komplexität zu erzielen. Beispiele sind: Dropout, L1- und L2-Regularisierung und Early Stopping. Bei Dropout werden zufällig ausgewählte Neuronen während des Trainings ausgeschaltet, um eine Überanpassung des Modells an die Trainingsdaten zu vermeiden. Die L1- und L2-Regularisierung Fürgen der Kostenfunktion eine zusätzliche Konstante zu, welche die große der Neuronen beschränkt und somit eine Überanpassung vermeidet. Das Early Stopping bezieht sich auf Überwachungskriterien. Sind diese Überwachungskriterien erfüllt wird das Training frühzeitig beendet. In diesem Projekt wurde die MINST-Database mit sehr großen Trainingsdatensätzen verwendet. Dadurch bestand die Gefahr von Overfitting, \cite{Over/Underfitting}.\\


 \section{Optimierungsproblem}
Unter dem Optimierungsproblem versteht man, dass finden des besten Satzes von Gewichten. Damit wird die Vorhersagefähigkeit verbessert, wodurch zusätzlich die Genauigkeit des Neuronen-Netzes verbessert wird. Die Kostenfunktion, welche die Soll- und Ist-Vorhersage des Modells misst, wird angepasst. Danach werden die Gewichte angepasst, um den Fehler zu minimieren. Es existieren verschiedene Algorithmen für dieses Problem, wie den Gradientenabstieg. \\
Die Ableitungen der Kostenfunktion (Gradienten) werden berechnet, um die Richtung der Anpassung der Gewichte vorzugeben, in Richtung des Gardientenabstiegs. Damit dieses Verfahren einen Nutzen hat muss es mehrmals angewendet werden, bis die Fehlerfunktion minimal wird.
Dieses Verfahren ist einfach zu Implementieren und trägt zu einer besseren Generalisierung bei, \cite{OptPro}.\\


 \section{Overparametrization}
Existieren in einem Neuronen-Netzwerk zu viele Neuronen und Schichten welche nicht den Anforderungen und Aufgaben des Netzwerkes entsprechen, dann spricht man von Overparametrization. 
Wenn es zu viele Neuronen und Schichten gibt hat das Netzwerk zu viel ungenutzte Freiheiten sich an das Muster der Trainingsdaten anzupassen. Wenn es zu wenige Neuronen und Schichten hat, kann das Netz das Muster der Trainingsdaten nicht erfassen. Um Overparametrization zu vermeiden muss die Anzahl der Parameter sorgfältig gewählt werden. Um Overparametrisation zu vermeiden, ist es wichtig, ein Modell mit einer angemessenen Anzahl von Parametern zu wählen, die auf die verfügbaren Daten und das Problem, das gelöst werden soll, abgestimmt ist. Dies kann durch eine sorgfältige Auswahl der Architektur, Regulierung und Reduktion der Anzahl der Neuronen oder Schichten erreicht werden, \cite{Over/Underfitting}.\\


\chapter{Fazit}
Zusammenfassend lässt sich sagen, dass das Projekt, bei dem ein neuronales Netzwerk Verwendung findet, um handgeschriebene Ziffern aus dem MNIST-Datensatz zu identifizieren, eine Herausforderung für jeden, der sich für den Bereich des maschinellen Lernens interessiert, aber auch eine große Chance bietet, die Fähigkeiten in diesem Bereich zu verbessern.\\ Durch die Verwendung des MNIST-Datensatzes kann das neuronalen Netzwerk trainiert werden, um handgeschriebene Ziffern mit hoher Genauigkeit zu erkennen. \\

Jedoch ist es wichtig zu beachten, dass eine gründliche Vorbereitung der Daten ein wesentlicher Faktor für den Erfolg des Projekts ist. Dies beinhaltet die Überprüfung und Bereinigung der Daten, um sicherzustellen, dass sie geeignet für das Training des neuronalen Netzwerks sind. Ebenso ist es wichtig, die Hyperparameter sorgfältig einzustellen, um eine optimale Leistung des neuronalen Netzwerks zu erzielen. Außerdem kann es hilfreich sein, verschiedene Architekturen zu evaluieren, um das bestmögliche Ergebnis zu erzielen. \\

Insgesamt bietet das Projekt eine einzigartige Möglichkeit, die Fähigkeiten im Bereich des maschinellen Lernens zu verbessern und ein tieferes Verständnis für die Funktionsweise neuronaler Netzwerke zu erlangen.
%\newpage


\printbibliography
\end{document}

